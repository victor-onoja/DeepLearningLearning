{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6gjRtnBwNeXxf97TZWqCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor-onoja/DeepLearningLearning/blob/main/SingleLabelMulticlassClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFduf08dxf7s",
        "outputId": "0bcb3a5e-847d-4f39-ffe6-3adce47ec276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.3553 - loss: 3.2354 - val_accuracy: 0.6280 - val_loss: 1.8615\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.6717 - loss: 1.6644 - val_accuracy: 0.7070 - val_loss: 1.3700\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.7523 - loss: 1.1795 - val_accuracy: 0.7520 - val_loss: 1.1849\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.8007 - loss: 0.9582 - val_accuracy: 0.7770 - val_loss: 1.0592\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8345 - loss: 0.7806 - val_accuracy: 0.7900 - val_loss: 0.9806\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8636 - loss: 0.6645 - val_accuracy: 0.8130 - val_loss: 0.9238\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8877 - loss: 0.5497 - val_accuracy: 0.8090 - val_loss: 0.9003\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9057 - loss: 0.4603 - val_accuracy: 0.8140 - val_loss: 0.8743\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9233 - loss: 0.3762 - val_accuracy: 0.8170 - val_loss: 0.8548\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9335 - loss: 0.3278 - val_accuracy: 0.8160 - val_loss: 0.8890\n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.9399 - loss: 0.2886 - val_accuracy: 0.8090 - val_loss: 0.8948\n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9494 - loss: 0.2383 - val_accuracy: 0.8230 - val_loss: 0.8487\n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9519 - loss: 0.2111 - val_accuracy: 0.8250 - val_loss: 0.8553\n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9522 - loss: 0.1985 - val_accuracy: 0.8230 - val_loss: 0.8708\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9560 - loss: 0.1776 - val_accuracy: 0.8210 - val_loss: 0.8898\n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9581 - loss: 0.1613 - val_accuracy: 0.8110 - val_loss: 0.8990\n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9577 - loss: 0.1495 - val_accuracy: 0.8100 - val_loss: 0.9414\n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9568 - loss: 0.1388 - val_accuracy: 0.8220 - val_loss: 0.8907\n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9642 - loss: 0.1216 - val_accuracy: 0.8100 - val_loss: 0.9386\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9634 - loss: 0.1188 - val_accuracy: 0.8230 - val_loss: 0.9213\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "y_train = to_categorical(train_labels)\n",
        "y_test = to_categorical(test_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = y_train[:1000]\n",
        "partial_y_train = y_train[1000:]\n",
        "\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(46, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=9, batch_size=512)\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdOEvd1p3P9I",
        "outputId": "866596ca-07c8-4bb1-d2af-0cbea83e0354"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.3799 - loss: 3.2534\n",
            "Epoch 2/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.6504 - loss: 1.6708\n",
            "Epoch 3/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7253 - loss: 1.2450\n",
            "Epoch 4/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7865 - loss: 0.9923\n",
            "Epoch 5/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8266 - loss: 0.8058\n",
            "Epoch 6/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8583 - loss: 0.6687\n",
            "Epoch 7/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8819 - loss: 0.5585\n",
            "Epoch 8/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9019 - loss: 0.4647\n",
            "Epoch 9/9\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9195 - loss: 0.3872\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.9295\n",
            "[0.9503293633460999, 0.7831701040267944]\n"
          ]
        }
      ]
    }
  ]
}